#!/bin/bash
####################################################################################################################################################################
# UTILITY FUNCTIONS
####################################################################################################################################################################
secho() { # The "echo" builtin should not be used with arbitrary strings since it does not support termination of the parameter list
    printf '%s\n' "$*"
}

stdout() {
    secho "$@" >&1
}

stderr() {
    secho "$@" >&2
}

die() {
    stderr 'ERROR:' "$@"
    exit 1
}

err_handler() {
    die "error at line $1, last exit code is $2" 
}
####################################################################################################################################################################


####################################################################################################################################################################
# SHELL PARAMETERS
####################################################################################################################################################################
set -o nounset
set -o pipefail
set -o errexit
set -o errtrace
shopt -s nullglob
shopt -s failglob
trap 'err_handler "$LINENO" "$?"' ERR
####################################################################################################################################################################

####################################################################################################################################################################
# CONFIG
####################################################################################################################################################################
JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk.x86_64
MOGOOP_DIR=~/mogoop
NO_DEDICATED_MASTER_HOST=1 # Don't use a separate machine for Jobtracker/Namenode
PER_NODE_MAPPER_CORES=60	# TODO: Auto-config per machine. The HOSTS array already stores CPU count for each.
PER_NODE_REDUCER_CORES=60	# TODO: Auto-config per machine. The HOSTS array already stores CPU count for each.

# See https://mogon.zdv.uni-mainz.de/dokuwiki/local_scratch
LSF_JOB_TEMP_DIR="/jobdir/$LSB_JOBID"

NAMENODE_DATA_DIR="$LSF_JOB_TEMP_DIR/namenode-data"
DATANODE_DATA_DIR="$LSF_JOB_TEMP_DIR/datanode-data"
MAPRED_DATA_DIR="$LSF_JOB_TEMP_DIR/mapred-data"

HADOOP_DIR="$MOGOOP_DIR/hadoop"
HADOOP_MASTER_LIST="$HADOOP_DIR/conf/masters"
HADOOP_SLAVE_LIST="$HADOOP_DIR/conf/slaves"
HADOOP_CORE_SITE_XML="$HADOOP_DIR/conf/core-site.xml"
HADOOP_CORE_SITE_XML_TEMPLATE="./templates/hadoop-1.2.1/conf/core-site.xml"
HADOOP_HDFS_SITE_XML="$HADOOP_DIR/conf/hdfs-site.xml"
HADOOP_HDFS_SITE_XML_TEMPLATE="./templates/hadoop-1.2.1/conf/hdfs-site.xml"
HADOOP_MAPRED_SITE_XML="$HADOOP_DIR/conf/mapred-site.xml"
HADOOP_MAPRED_SITE_XML_TEMPLATE="./templates/hadoop-1.2.1/conf/mapred-site.xml"
####################################################################################################################################################################

####################################################################################################################################################################
# GLOBALS
####################################################################################################################################################################
declare -A HOSTS	# key = hostname, value = cpu count
HOST_SELF=
####################################################################################################################################################################


####################################################################################################################################################################
# THE ACTUAL CODE
####################################################################################################################################################################

main() {
	get_hosts

	stdout "Jobtracker / Namenode: $SELF"

	# If configured, don't dedicate the whole local machine as Jobtracker/Namenode.
	# It typically has 64 cores at Mogon which is quite a lot.
	if [ "$NO_DEDICATED_MASTER_HOST" -eq 0 ] ; then
		remove_host "$SELF"
	fi

	# Truncate masters file:
	# The local machine is automatically selected as master.
	# The purpose of the masters-list would be to add SECONDARY namenodes / jobtrackers - which we don't want.
	> "$HADOOP_MASTER_LIST"
	stdout "Secondary namenodes:" "$(<"$HADOOP_MASTER_LIST")"

	# Set all remaining hosts as slave
	stdout "Worker machines: ${!HOSTS[@]}"
	> "$HADOOP_SLAVE_LIST"
	for host in "${!HOSTS[@]}" ; do
		stdout "$host" >> "$HADOOP_SLAVE_LIST"
	done
    
	# core-site.xml: Set ourself as namenode
	replace_string_in_file 'MOGOOP_NAMENODE' "$SELF" "$HADOOP_CORE_SITE_XML_TEMPLATE" > "$HADOOP_CORE_SITE_XML"
	
	# hdfs-site.xml: Set namenode / datanode data dir
	replace_string_in_file 'MOGOOP_NAMENODE_DATA_DIR' "$NAMENODE_DATA_DIR" "$HADOOP_HDFS_SITE_XML_TEMPLATE" > "$HADOOP_HDFS_SITE_XML.temp"
	replace_string_in_file 'MOGOOP_DATANODE_DATA_DIR' "$DATANODE_DATA_DIR" "$HADOOP_HDFS_SITE_XML.temp" > "$HADOOP_HDFS_SITE_XML"
	
	# mapred-site.xml: Set ourself as jobtracker, data dir for mappers/reducers, and number of mapper/reducer cores per node.
	replace_string_in_file 'MOGOOP_JOBTRACKER' "$SELF" "$HADOOP_MAPRED_SITE_XML_TEMPLATE" > "$HADOOP_MAPRED_SITE_XML.temp1"
	replace_string_in_file 'MOGOOP_MAPRED_DATA_DIR' "$MAPRED_DATA_DIR" "$HADOOP_MAPRED_SITE_XML.temp1" > "$HADOOP_MAPRED_SITE_XML.temp2"
	replace_string_in_file 'MOGOOP_PER_NODE_MAPPER_CORES' "$PER_NODE_MAPPER_CORES" "$HADOOP_MAPRED_SITE_XML.temp2" > "$HADOOP_MAPRED_SITE_XML.temp3"
	replace_string_in_file 'MOGOOP_PER_NODE_REDUCER_CORES' "$PER_NODE_REDUCER_CORES" "$HADOOP_MAPRED_SITE_XML.temp3" > "$HADOOP_MAPRED_SITE_XML"
	
	export JAVA_HOME

	"$HADOOP_DIR/bin/start-dfs.sh"

	stdout "Hadoop cluster running. Opening shell so you can use it."
	stdout "Exit the shell to terminate the Hadoop cluster."

	bash -i

	"$HADOOP_DIR/bin/stop-dfs.sh"
}

get_hosts() {
	local -a hosts_temp
	# Get all hosts of the LSF job. Its a list of pairs: First item = hostname, second = cpu count
	read -ra hosts_temp <<< "$LSB_MCPU_HOSTS"

	local i=0
	for ((i=0; i < ${#hosts_temp[@]}; i+=2)) ; do
		local host="${hosts_temp[$i]}"
		local cpu_count="${hosts_temp[$(($i+1))]}"
		HOSTS[$host]=$cpu_count
		stdout "Host $host: $cpu_count cpus"
	done

	# Get host where this script is running
	SELF="$(hostname --short)" # --short removes the domain name, which get_hosts_sorted won't include
}

remove_host() {
	unset "HOSTS[$1]"
}

# Inspired by http://mywiki.wooledge.org/BashFAQ/021
# $1 = to replace (bash matching pattern)
# $2 = replacement
# $3 = input file
replace_string_in_file() {
	while IFS= read -r line; do
		stdout "${line//"$1"/$2}"
	done < "$3"
}

main "$@"

####################################################################################################################################################################
